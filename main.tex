\documentclass[11pt, openright]{book}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning}
    % Cover Variables
    \newcommand{\ctoptitle}{Co-Design}
    \newcommand{\ctitle}{-- Rapport de TP --}
    \newcommand{\cautor}{\Large{Bastien DESCOS}}
    \newcommand{\cdate}{28.01.2026}
    \newcommand{\sectittle}{}


    % Header Variables
        \newcommand{\headRE}{Co-Design~--~Rapport de TP}
        \newcommand{\headLE}{\emph{\rightmark}}
        \newcommand{\footRE}{B.Descos $-$ \cdate}
        \newcommand{\footLE}{\emph{\thepage}}

    % TOC Variables
        \newcommand{\toctitle}{Table des Matières}
        
        \newcommand{\tocchapter}{Chapter}
        \newcommand{\toccount}{3}
  
    % Chapter Variables
        \newcommand{\chvar}{Chapter -}

    % Other Variables
        \newcommand{\figcountdepth}{1}

\input{./template/common/style.tex}
\input{./template/common/math.tex}
\input{./template/common/header.tex}
\input{./template/common/toc.tex}

    % figure support
    \usepackage{import}
    \usepackage{xifthen}
    \pdfminorversion=7
    \usepackage{pdfpages}
    \usepackage{transparent}
    \newcommand{\incfig}[1]{%
            \def\svgwidth{\columnwidth}
            \import{./figures/}{#1.pdf_tex}
    }

    \pdfsuppresswarningpagegroup=1

    \newcommand*\circled[1]{\tikz[baseline= (char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}


\begin{document}
% Spacing
\input{./template/common/begin.tex}

% Cover
\input{./template/common/cover.tex}
    
\pagestyle{fancy}

\newpage
\section{Notebook exemple cybersécurité}
\subsection{Présentation du dataset}
Le dataset que nous allons utiliser est le UNSW-NB15, ce dataset a initialement 2,540,044 entrées réparties en 4 fichiers principaux.
Nous allons utiliser 175,341 enregistrements en tant que base de données d'entraînement ainsi que 82,332 en tant que base de données de test. \newline
Il contient différent types d'attaque permettant d'entraîner le modèle pour reconnaître ces attaques:
\begin{itemize}
    \item Fuzzers
    \item Analysis
    \item Backdoors
    \item DoS
    \item Exploits
    \item Generic
    \item Reconnaissance
    \item Shellcode
    \item Worms
\end{itemize}

En l'occurrence, la version que nous téléchargeons est une version pré-quantifiée ce qui  nous permettra un temps de téléchargement beaucoup plus court.

La sortie du réseau est simplement un retour qui indique si l'entrée est suspicieuse ou si elle est seine grâce à une probabilité allant de 0 (l'entrée est sûre) à 1 (l'entrée est suspecte).

\subsection{Entrainement MLP}

\subsubsection{Modèle} 

Le réseau est un MLP avec 593 entrées, 3 couches cachées de 64 neurones, et une couche de sortie de 1 neurone. 
On retrouve donc 1 sortie qui indique la probabilité que l'entrée soit une attaque ou non. \newline
Un modèle MLP (Multi-Layer Perceptron) est un réseau de neurones artificiels composé de plusieurs couches de neurones entièrement connectées.
Chaque neurone dans une couche est connecté à tous les neurones de la couche suivante. \newline
Cela nous fait un total de 593$\times$64 + 64$\times$64 + 64$\times$64 + 64$\times$1 = 38,081 poids. \newline
Le modèle est entraîné avec une fonction de perte binaire cross-entropy et l'optimiseur Adam.
L'entraînement est effectué sur 10 époques avec un batch size de 256.

\subsubsection{Quantification} 

Nous utilisons une quantification pour nos poids ainsi que nos ReLu de 2 bits.

Il existe plusieurs types de quantification, nous utilisons ici une quantification binaire.
Pour la quantification binaire, les poids prennent seulement 2 valeurs possibles: 0 et 1.

Pour la quantification, il exite plusieurs méthodes: QAT (quantization-aware training) et PTQ (post-training quantization). 
La première méthode consiste à quantifier durant l'entraînement, la seconde consiste à quantifier après l'entraînement.
La quantification utilisée dans notre projet est une quantification QAT.\@

\subsubsection{FINN}

Le framework FINN est un framework open-source développé par Xilinx pour la conception et le déploiement de réseaux de neurones quantifiés sur des FPGA.\@
Il sert d'interface entre le ONNX et Vitis. Il nous permet donc de ne pas avoir à créer le HLS à la main et donc nous simplifie grandement la tâche. \newline
FINN utilise dans notre cas une quantifiaction binaire pour les poids et les activations, ce qui permet de réduire considérablement la taille du modèle et d'améliorer la vitesse d'inférence sur le FPGA.\newline
Le modèle quantifié est ensuite converti en une représentation compatible avec le matériel FPGA à l'aide de FINN, qui génère du code HDL (Hardware Description Language) pour l'implémentation sur le FPGA.\newline
FINN offre également des outils pour l'optimisation du modèle, la génération de bitstreams pour le FPGA.\@

Pour l'importation dans FINN, on ajoute 7 zéros afin de passer d'un nb premier 593, à un nb facilement découpable (600): W_new = np.pad (W_orig, [(0,0), (0,7)]).

Pour que FINN fonctionne, il necessite une quantification binaire codée entre \{-1, +1\}, c'est pourquoi nous avons dû adapter notre modèle Brevitas pour qu'il corresponde à cette contrainte.
Pour ce faire nous avons utilisé un wrapper Brevitas qui convertit les poids et les activations de \{0, 1\} à \{-1, +1\}.

FINN sort beaucoup de fichiers de sortie, certains peuvent être très imposant comme le bitfile, c'est pourquoi il y a des paramètres afin de gérer les fichiers de sortie:
\begin{itemize}
    \item \textbf{ESTIMATE\_REPORTS}: fourni les rapports des ressources attendues et des performances par couche et pour l'ensemble du réseau sans synthèse Vivado complète;
    \item \textbf{STITCHED\_IP}: crée un design IP stream-in stream-out qui peut être intégré dans d'autres designs Vivado IPI ou RTL;\@
    \item \textbf{RTLSIM\_PERFORMANCE}: utiliser PyVerilator pour effectuer un test de performance/latence du design STITCHED_IP;\@
    \item \textbf{OOC\_SYNTH}: exécuter une synthèse hors contexte (juste l'accélérateur lui-même, sans aucun système l'entourant) sur le design STITCHED_IP pour obtenir les ressources FPGA post-synthèse et la fréquence d'horloge réalisable;
    \item \textbf{BITFILE}: intégrer l'accélérateur dans un shell pour produire un bitfile autonome;
    \item \textbf{PYNQ\_DRIVER}: générer un pilote Python PYNQ qui peut être utilisé pour lancer l'accélérateur;
    \item \textbf{DEPLOYMENT\_PACKAGE}: créer un dossier contenant les sorties BITFILE et \newline PYNQ\_DRIVER, prêt à être copié vers la plateforme FPGA cible.
    \item \textbf{OUTPUT\_DIR}: indique le dossier dans lequel l'ensemble des sorties du programmes seront écrites.
    \item \textbf{STEPS}: indique la liste des étapes prédefinie ou personnalisée que FINN va faire pour le build de l'accélérateur.
\end{itemize}
Pour le déploiement sur la carte nous aurons besoin du BITFILE ainsi que du PYNQ\_DRIVER.\@ L'ESTIMATE\_REPORTS peut être utile en amont pour savoir les ressources et les performances de notre accélérateur.\@

\subsection{Comparaison des performances}
Nous allons faire varier la quantification des poids et des activations de 2 bits à 16 bits et comparer les performances du modèle sur le dataset UNSW-NB15.\newline
Nous allons mesurer la précision (accuracy) ainsi que le temps d'inférence sur CPU.\@ \newline
Voici les résultats obtenus: 

\begin{center}
\begin{tabular}{|l|*{4}{c|}r|}

 \hline
   Modèle & MLP & MLP & MLP & MLP & MLP \\ \hline
   Nb quantification & 2 & 4 & 8 & 16 & 32 \\
   Accuracy (\%) & 73.5 & 79.2 & 81.3 & 82.1 & 82.3 \\
   Avg Loss & 0.6012 & 0.5123 & 0.4789 & 0.4567 & 0.4501 \\
   Temps CPU (s) & 12.34 & 13.45 & 14.56 & 15.67 & 16.78 \\
   Temps Inférence (s) & 0.001234 & 0.001345 & 0.001456 & 0.001567 & 0.001678 \\
   Temps inférence (ms) & 1.234 & 1.345 & 1.456 & 1.567 & 1.678 \\
   Nb Inférences/s & 810 & 743 & 686 & 638 & 596 \\
 \hline  
 \end{tabular}
\end{center}

Comme nous pouvons le voir, la quantification a un impact significatif sur les performances du modèle.
En effet, plus la quantification est faible, plus la précision diminue. Cependant, le temps d'inférence diminue également, ce qui peut être bénéfique pour les applications en temps réel.\@
Nous remarquons aussi que la diminution de la précision n'est pas linéaire par rapport à la taille de la quantification. En effet, dès que la quantification est de 4 bits, nous observons une accuracy qui est très semblable.\newline
Il est donc important de trouver un compromis entre la taille de la quantification et les performances du modèle en fonction des besoins de l'application.\@

\subsection{Estimations implémentations FINN}
Les max FPS visés sont de 1 000 000 (1 MOps). 
La période est de 10ns soit une fréquence de 100 000 000 Hz, soit 100MHz.\newline 
En baissant TARGET_FPS, nous pouvons réduire la configuration matérielle nécessaire.\newline
Coté ressource, le programme estime les utilisations suivantes:
\begin{itemize}
    \item LUT: 9354 
    \item BRAM\_18K: 45
\end{itemize}

Les performances estimées sont de 1 562 500,0 FPS.

L'architecture comporte les élements suivants: 
\begin{itemize}
\item "PE": 16 + 1 + 1 +1 = 19	
\item "SIMD": 40 + 64 + 64 + 1 = 169
\end{itemize}

B. Partie Stitched IP et PYNQ bitfile and Driver

Estimation par FINN:
\begin{itemize}	
\item LUT: 17640 + 1096 + 1042 + 268 = 20046		
\item BRAM\_18K = 0
\item FF: 2037 + 801 + 803 + 68 = 3909			
\item DSP = 32 + 32 + 1 = 65
\end{itemize}	

Les performances estimées par FINN sont de 448430.49327354255 FPS.

Les FIFOS permettent de passer les informations d'une couche à une autre ainsi que de synchroniser l'ensemble. 
Ici elles sont de 32 à 2 entre la couche d'entrée et le couche 1 puis de 2 à 2 entre les autres couches. Cela veut donc dire que les couches ont besoin d’un certain nombre d’entrées pour pouvoir fonctionner (ici 2).


\subsection{Synthèse Vivado}
Nous pouvons maintenant regarder les ressources utilisées après synthèse Vivado.
Pour les lire, nous nous sommes rendus dans le rapport post synthèse Vivado qui est parmi les rapports dans le final output du programme 3.
Nous obtenons les résultats suivants:
\begin{itemize}
    \item LUT: 12711
    \item BRAM\_18K: 2
    \item FF: 15854
    \item BRAM\_36K: 22
    \item DSP: 129
    \item SRL: 381
\end{itemize}
Pour ouvrir Vivado, nous devons definir l'environnement avec la commande suivante en étant à la racine:
\begin{verbatim}
source /etc/Xilinx/Vivado/2020.2/settings64.sh
\end{verbatim}
Puis nous ouvrons Vivado en étant dans le dossier /tmp et dans le sous dossier créé par le programme 3 avec la commande:
\begin{verbatim}
vivado finn_zynq_link.xpr
\end{verbatim}
Les valeurs indiqués dans le rapport post-synthèse sont également retrouvable au sein de Vivado dans les ressources implémentées:

\begin{figure}[H]
\centering
\includegraphics{Images/Graph_Utilisation_Table_unsw.png}
\caption{Tableau de l'utilisation des ressources}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{Images/Graph_Utilisation_Graph_unsw.png}
\caption{Graphique de l'utilisation des ressources}
\end{figure}

Comme nous pouvons le voir, l'utilisation des ressources est très faible par rapport aux ressources disponibles sur la carte FPGA.\@
On voit que les ressources utilisées sont largement inférieures aux ressources estimées par FINN.\@
Cela peut être dû à plusieurs facteurs, notamment les optimisations effectuées par le synthétiseur Vivado qui peuvent réduire l'utilisation des ressources par rapport aux estimations initiales de FINN.\@

La répartition des ressources utilisées est la suivante:
\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{Images/Implem_Ressources_FPGA_unsw.png}
\caption{Image de la répartition des ressources utilisées}
\end{figure}
Nous pouvons croire que la majorité des ressources sont utilisées mais en réalité, nous voyons bien dans la table ainsi que dans le graphique que l'utilisation des ressources est très faible par rapport aux ressources disponibles sur la carte FPGA.\@
La présence de bleu de partout dans l'image explique juste un grand étalement des ressources utilisées sur la carte.\@
\subsection{Carte}
Ici je dois mettre ce que le prof envoi en sceenshot et aussi faire un équivalent entre FPGA et CPU/GPU.\@

\section{Modification MLP pour MNIST}

\subsection{MNIST dans FINN}
Le dataset MNIST est un ensemble de données utilisé pour la reconnaissance de chiffres manuscrits.
Il contient 60,000 images d'entraînement et 10,000 images de test, chaque image étant une image en niveaux de gris de 28$\times$28 pixels représentant un chiffre de 0 à 9. \newline
Afin de nous servir de MNIST, nous allons utiliser à nouveau le framework FINN.\@

\subsection{Impact de la quantification}
Ici je dois mettre les résultats d'impact de la quantification sur MNIST / CIFFAR10.
Afin de réaliser la quantification, nous allons utiliser Brevitas qui est une bibliothèque de quantification pour PyTorch.
Pour ce faire, nous avons utilisé des couches de Brevitas pour remplacer les couches standards de PyTorch.
Cela s'effectue comme suit:
\begin{verbatim}
import brevitas.nn as qnn
qnn.QuantConv2d(3, 6, kernel_size=5, bias=True, padding = 2, weight_bit_width=16)
\end{verbatim}
Nous voyons dans cette ligne la définition d'une couche de convolution quantifiée avec des poids sur 16 bits (weight\_bit\_width=16).
Le reste ne change pas par rapport à une couche de convolution standard de PyTorch.

Pour réaliser l'impact de la quantification, nous avons entraîné plusieurs modèles avec des poids et des activations de différentes tailles (2, 4, 8, 16 bits) et nous avons comparé les performances de ces modèles sur le dataset CIFFAR10.
Nous avons également comparé ces modèles avec un modèle non quantifié (poids et activations en 32 bits flottants). \newline
Pour les modèles utilisés nous avons utilisé un modèle simple de CNN avec 2 couches de convolution suivies de 2 couches fully connected type LeNet-5. \newline
Nous avons également utilisé un modèle de MLP avec 3 couches soit 1 couche d'entrée (100 neurones), une couche cachée (50 neurones), et une couche de sortie (10 neurones).\newline
Les métriques pour la mesure seront la précision (accuracy) ainsi que le temps d'inférence.

\begin{tabular}{| l |*{6}{c |} r | }
 \hline			
   Modèle & CNN & CNN & CNN & CNN & CNN & CNN \\ \hline
   Nb quantification & 1 & 2 & 4 & 8 & 16 & 32 \\
   Accuracy (\%) & 10 & 56.2 & 61.2 & 63.6 & 64.9 & 64.4 \\
   Avg Loss & NaN & 1.257583 & 1.112131 & 1.048991 & 1.024594 & 1.026724 \\
   Temps CPU (s) & 4.574 & 3.6179 & 4.1767 & 5.34 & 4.0933 & 6.4669 \\
   Temps Inférence (s) & 0.0004574 & 0.00036179 & 0.00041767 & 0.000534 & 0.00040933 & 0.00064669 \\
   Temps inférence (ms) & 0.4574 & 0.36179 & 0.41767 & 0.534 & 0.40933 & 0.64669 \\
   Nb Inférences/s & 2186 & 2765 & 2394 & 1872 & 2443 & 1545 \\
 \hline  
 \end{tabular}

\subsection{Performances estimées}
Ici je dois mettre les résultats d'estimations FINN, avec les ressources utilisées, la fréquence max, etc.
Ainsi que la synthèse Vivado avec les ressources utilisées, la fréquence max, etc.

\newpage
\section{Bibliographie}
Liens vers les références utilisées pour la réalisation du rapport: \newline
\url{https://www.kaggle.com/code/mrwellsdavid/unsw-nb15-dataset-mlp-classifier/notebook} \newline
\url{https://xilinx.github.io/brevitas/v0.12.1/tutorials/tvmcon2021.html} \newline
\url{https://github.com/Xilinx/brevitas?tab=readme-ov-file} \newline
\url{https://arxiv.org/pdf/2103.13630} \newline

\end{document}